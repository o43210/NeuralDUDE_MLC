{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import binary_dude as bd\n",
    "\n",
    "from numpy import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras as K\n",
    "import sys\n",
    "\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import models\n",
    "from keras import utils\n",
    "from keras.utils.training_utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "K.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.025 1.25  0.   ]\n",
      " [1.025 0.    1.25 ]]\n",
      "(65536,)\n",
      "[1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# n=1000000\n",
    "alpha=0.1\n",
    "delta=0.1\n",
    "nb_classes=2\n",
    "L=np.array([[delta, -delta/(1-2*delta), (1-delta)/(1-2*delta)],[delta, (1-delta)/(1-2*delta), -delta/(1-2*delta)]])\n",
    "L_new=-L+(1-delta)/(1-2*delta)     # A new loss matrix\n",
    "k_max=40\n",
    "\n",
    "print L_new\n",
    "\n",
    "n = 65536\n",
    "x = bd.bsmc(n, alpha)\n",
    "z = bd.bsc(x,delta)\n",
    "Z=utils.np_utils.to_categorical(z,nb_classes)\n",
    "\n",
    "print x.shape\n",
    "print z[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural DUDE with different window size\n",
    "* 아래 코드는 delta = 0.1 인 상태에서 window size를 달리하여 error rate을 구하는 코드이다.\n",
    "\n",
    "ipython notebook으로 돌릴 경우\n",
    "\n",
    "    #k1 = int(sys.argv[1])\n",
    "    #k2 = int(sys.argv[2])\n",
    "    #gpu_num = int(sys.argv[3])\n",
    "    \n",
    "    k1 = ?\n",
    "    k2 = ?\n",
    "    gpu_num = ?\n",
    "    \n",
    "위 경우처럼 돌려야 함.\n",
    "\n",
    "python file 로 돌릴경우\n",
    "\n",
    "    k1 = int(sys.argv[1])\n",
    "    k2 = int(sys.argv[2])\n",
    "    gpu_num = int(sys.argv[3])\n",
    "    \n",
    "    #k1 = ?\n",
    "    #k2 = ?\n",
    "    #gpu_num = ?\n",
    "    \n",
    "python file 실행할 때 argument로 k1, k2, gpu_num을 설정해 주어야함. 아래와 같이 screen 에서 명령어 입력.\n",
    "\n",
    "    \"\"CUDA_VISIBLE_DEVICES=? k1 k2 ?\"\"\n",
    "    CUDE_VISIBLE_DEVICES=0 1 4 0 1 -> 이렇게 돌리면 됨. \n",
    "    위와 같이 돌리면 window size = 1~4로 GPU0에 돌린다.\n",
    "    \n",
    "    CUDE_VISIBLE_DEVICES=0 1 4 0\n",
    "    CUDE_VISIBLE_DEVICES=1 5 8 1\n",
    "    CUDE_VISIBLE_DEVICES=2 9 12 2\n",
    "    CUDE_VISIBLE_DEVICES=3 13 15 3\n",
    "    -> 이렇게 4개의 GPU에 4개의 코드를 돌리면 효율적임.\n",
    "    \n",
    "* 이렇게 설정한 이유는 여러 GPU에 서로 다른 코드를 돌리기 위함임.\n",
    "* 그리고 결과는 text file로 저장하세요... 아래와 같이 저장하면 됩니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ba1b2e6634a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mk2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgpu_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Neural_DUDE_gpu%d\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mgpu_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '-f'"
     ]
    }
   ],
   "source": [
    "#k1 = int(sys.argv[1])\n",
    "#k2 = int(sys.argv[2])\n",
    "#gpu_num = int(sys.argv[3])\n",
    "\n",
    "k1 = 1\n",
    "k2 = 4\n",
    "gpu_num = 0\n",
    "\n",
    "f = open(\"NeuralDUDE_k_gpu%d.txt\"%gpu_num, \"w\")\n",
    "f.write(\"gpu%d result\\n\"%gpu_num)\n",
    "f.close()\n",
    "for k in xrange(k1, k2+1):\n",
    "    \n",
    "    C,Y = bd.make_data_for_ndude(Z,k,L_new,nb_classes,n)\n",
    "\n",
    "    #--------------------------------------------------------------------------#\n",
    "    #----------------------------Neural Net model------------------------------#\n",
    "    inputs = layers.Input(shape = (2 * k * nb_classes,))\n",
    "    layer = layers.Dense(40, kernel_initializer = 'he_normal')(inputs)\n",
    "    layer = layers.Activation('relu')(layer)\n",
    "    layer = layers.Dense(40, kernel_initializer = 'he_normal')(layer)\n",
    "    layer = layers.Activation('relu')(layer)\n",
    "    layer = layers.Dense(40, kernel_initializer = 'he_normal')(layer)\n",
    "    layer = layers.Activation('relu')(layer)\n",
    "    layer = layers.Dense(3, kernel_initializer = 'he_normal')(layer)\n",
    "    outputs = layers.Activation('softmax')(layer)\n",
    "    model = models.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "    adam = optimizers.Adam()\n",
    "    model.compile(loss='poisson', optimizer=adam)\n",
    "\n",
    "    model.fit(C,Y,epochs=10,batch_size=100, verbose=0, validation_data=(C, Y))\n",
    "    #--------------------------------------------------------------------------#\n",
    "    #--------------------------------------------------------------------------#\n",
    "\n",
    "    pred_prob = model.predict(C, batch_size = 200, verbose = 0)\n",
    "    pred_class = np.argmax(pred_prob, axis = 1)\n",
    "    s_nn_hat=hstack((zeros(k),pred_class,zeros(k)))\n",
    "    x_nn_hat=bd.denoise_with_s(z,s_nn_hat,k)\n",
    "    error_nn=bd.error_rate(x,x_nn_hat)\n",
    "    \n",
    "    print 'k:%d error_nn=%f'%(k, error_nn)\n",
    "    \n",
    "    with open(\"NeuralDUDE_k_gpu%d.txt\"%gpu_num, \"a\") as f:\n",
    "        f.write('k:%d error_nn=%f\\n'%(k, error_nn))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
